{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'santander-product-recommendation/train_dir/train_ver2.csv'\n",
    "limit_rows = 200000\n",
    "train_data = pd.read_csv(train_path, dtype = {'sexo':str, 'ind_nuevo':str,\n",
    "                                              'ult_fec_cli_1t':str,\n",
    "                                              'indext':str}, nrows = limit_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Columns to English\n",
    "train_data.columns = ['Status_Dt', 'Cust_ID', 'Emp_Status', 'Cust_Ctry', 'Cust_Sex', 'Age', 'Join_Dt',\n",
    "                'Is_New_Cust', 'Cust_Since', 'Relship_Status','Lst_Dt_Primary_Cust', 'Cust_Type_Mth_Beg', \n",
    "                'Cust_Relship_Type_Mth_Beg', 'Residence_Ctry', 'Is_Foreigner', 'Is_Spouse_Emp', 'Join_Channel', 'Deceased_Flg', \n",
    "                'Address_Type', 'Cust_Province_Cd', 'Cust_Province_Name', 'Cust_Active_Status', 'Gross_HHLD_Income',\n",
    "                'Cust_Segment', 'Savings_Acct', 'Guarantees', 'Cur_Acct', 'Derivative_Acct', 'Payroll_Acct',\n",
    "                'Junior_Acct', 'Mas_Particular_Acct', 'Particular_Acct', 'Particular_Plus_Acct', 'Short_Term_Deposits',\n",
    "                'Med_Term_Deposits', 'Long_Term_Deposits', 'e-Acct', 'Funds', 'Mortgage', 'Pension1', 'Loans',\n",
    "                'Taxes', 'Credit_Card', 'Securities', 'Home_Acct', 'Payroll', 'Pension2', 'Direct_Debit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing Age and Cust_Since\n",
    "train_data[\"Age\"]   = pd.to_numeric(train_data[\"Age\"], errors=\"coerce\")\n",
    "train_data[\"Cust_Since\"]   = pd.to_numeric(train_data[\"Cust_Since\"], errors=\"coerce\")\n",
    "train_data[\"Gross_HHLD_Income\"]   = pd.to_numeric(train_data[\"Gross_HHLD_Income\"], errors=\"coerce\")\n",
    "train_data = train_data.drop(['Pension2'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unimportant_features = ['Status_Dt','Cust_ID','Join_Dt','Is_New_Cust','Relship_Status','Lst_Dt_Primary_Cust',\n",
    "                       'Cust_Ctry','Relship_Status','Address_Type','Cust_Province_Name','Cust_Active_Status']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Payroll'] = train_data['Payroll'].fillna(0)\n",
    "med = train_data['Gross_HHLD_Income'].median()\n",
    "train_data['Gross_HHLD_Income'] = train_data['Gross_HHLD_Income'].fillna(med)\n",
    "train_data.drop(columns=['Is_Spouse_Emp', 'Lst_Dt_Primary_Cust'], inplace=True)\n",
    "train_data['Cust_Type_Mth_Beg'] = train_data['Cust_Type_Mth_Beg'].apply(lambda x: x[0] if isinstance(x,str) else str(x)[0])\n",
    "train_data = train_data.dropna(subset = ['Emp_Status','Cust_Sex','Age','Cust_Since','Cust_Type_Mth_Beg', 'Cust_Relship_Type_Mth_Beg' , 'Residence_Ctry', 'Is_Foreigner', 'Join_Channel', 'Deceased_Flg','Cust_Province_Cd','Cust_Segment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ['Age',\n",
    "'Cust_Since',\n",
    "'Gross_HHLD_Income',\n",
    "'Emp_Status',\n",
    "'Cust_Type_Mth_Beg',\n",
    "'Cust_Relship_Type_Mth_Beg',\n",
    "'Join_Channel',\n",
    "'Cust_Province_Cd',\n",
    "'Cust_Segment',\n",
    " 'Residence_Ctry',\n",
    "'Is_Foreigner',\n",
    "'Deceased_Flg']\n",
    "X = train_data.loc[:, inputs]\n",
    "y = train_data.iloc[:, 22:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y.to_numpy(), stratify=y.to_numpy()[:,1], test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, stratify = y_dev[:, 1], test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalable = ['Age', 'Cust_Since', 'Gross_HHLD_Income']\n",
    "one_hot = ['Emp_Status',\n",
    " 'Cust_Type_Mth_Beg',\n",
    "'Cust_Relship_Type_Mth_Beg',\n",
    "'Join_Channel',\n",
    "'Cust_Province_Cd',\n",
    "'Cust_Segment']\n",
    "ordinal = ['Residence_Ctry','Is_Foreigner','Deceased_Flg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "transformer = make_column_transformer(\n",
    "    (MinMaxScaler(), scalable),\n",
    "    (OneHotEncoder(handle_unknown='infrequent_if_exist'), one_hot),\n",
    "    (OrdinalEncoder(), ordinal)\n",
    ")\n",
    "\n",
    "X_train = transformer.fit_transform(X_train).toarray()\n",
    "X_val = transformer.transform(X_val).toarray()\n",
    "X_test = transformer.transform(X_test).toarray()\n",
    "X_dev = transformer.transform(X_dev).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "def apk(actual, predicted, k):\n",
    "    num_actual_products = sum(actual)\n",
    "    expected_products = np.where(actual==1)[0]\n",
    "    precision_at_k = []\n",
    "    for i in range(1,k+1):\n",
    "        num_hits = sum([recommended_product in expected_products \n",
    "             for recommended_product in np.argsort(predicted)[-i:]])\n",
    "        proportion_of_hits = num_hits/i\n",
    "        precision_at_k.append(proportion_of_hits*(np.argsort(predicted)[-i:][0] in expected_products))\n",
    "    return sum(precision_at_k)/min(k,num_actual_products) if min(k,num_actual_products)!= 0 else 0\n",
    "\n",
    "def mapk(actual, predicted, k):\n",
    "    average_precisions = []\n",
    "    i = 0\n",
    "    start = timeit.default_timer()\n",
    "    for a,p in zip(actual, predicted):\n",
    "        average_precisions.append(apk(a,p,k))\n",
    "        i+=1\n",
    "        if i%100000 == 0:\n",
    "            stop = timeit.default_timer()\n",
    "            print(f\"{stop-start} - {i} predictions have been processed with a MAP of {np.mean(average_precisions)}\")\n",
    "            start = timeit.default_timer()\n",
    "            break\n",
    "    return np.mean(average_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:   43.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    6.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 150, 'max_depth': 10}\n",
      "0.8709687824129119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:   54.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    8.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 150, 'max_depth': 15}\n",
      "0.8775615870067321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   59.6s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   10.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 150, 'max_depth': 15}\n",
      "0.8717173960918158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   10.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 200, 'max_depth': 15}\n",
      "0.8778335664926161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   57.7s\n",
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed:   14.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 200, 'max_depth': 15}\n",
      "0.8715244294653444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed:   12.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 250, 'max_depth': 15}\n",
      "0.877947005410477\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "num_est = [150, 200, 250]\n",
    "max_depth = [10, 15]\n",
    "best_params = {}\n",
    "max_score = -1\n",
    "for e in num_est:\n",
    "    for d in max_depth:\n",
    "        rf = RandomForestClassifier(verbose=1, n_estimators=e, max_depth=d, n_jobs=4)\n",
    "        rf.fit(X_dev, y_dev)\n",
    "        pred_rf = rf.predict(X_val)\n",
    "        score = mapk(y_val, pred_rf, 7)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_params['n_estimators'] = e\n",
    "            best_params['max_depth'] = d\n",
    "        print(best_params)\n",
    "        print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   48.1s\n",
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed:   13.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Training the Optimal Model\n",
    "rf_tuned = RandomForestClassifier(verbose=1, n_estimators=best_params['n_estimators'], max_depth=best_params['max_depth'], n_jobs=4)\n",
    "rf_tuned.fit(X_train, y_train)\n",
    "score_final = mapk(y_test, rf_tuned.predict(X_test), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8744820462189447"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
